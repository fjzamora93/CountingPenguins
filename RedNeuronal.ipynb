{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Convertir las coordenadas del CSV en bounding boxes\n",
    "\n",
    "Las coordenadas que tienes (Top_Left_X, Top_Left_Y, Bottom_Right_X, Bottom_Right_Y) definen rectángulos donde se encuentran los pingüinos en la imagen. Estas coordenadas serán las \"bounding boxes\" o cajas delimitadoras que tu modelo de detección de objetos debe aprender a predecir.\n",
    "\n",
    "Tendrás que asegurarte de que estas coordenadas estén en el formato correcto (si ya están en píxeles, estás listo). Si estuvieran en un sistema de referencia espacial, puedes transformarlas a píxeles para que sean compatibles con las imágenes TIFF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Generar etiquetas en formato YOLO o Faster R-CNN\n",
    "\n",
    "Dependiendo del modelo que elijas, deberás convertir las coordenadas en el formato específico que requieren los frameworks de entrenamiento. Para YOLO, las etiquetas deberían estar en un formato como [class_id, center_x, center_y, width, height] normalizado entre 0 y 1. Para Faster R-CNN, puedes mantener el formato como xmin, ymin, xmax, ymax sin normalizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Preparar el dataset\n",
    "Asegúrate de organizar tus datos en carpetas: una para las imágenes TIFF y otra para los archivos de anotación.\n",
    "Divídelo en conjuntos de entrenamiento, validación y prueba. Normalmente, una división de 70/20/10% es común, pero puedes ajustarlo según el tamaño del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Configurar el modelo\n",
    "\n",
    "### 2.1 Seleccionar el backbone\n",
    "Como mencionas, algunos de los backbones populares incluyen ResNet-34, DarkNet-53 o el Swin-Transformer. Aquí dependerá de los recursos de hardware y tu objetivo en cuanto a velocidad y precisión:\n",
    "\n",
    "- ResNet es conocido por ser robusto y ampliamente utilizado.\n",
    "- DarkNet es el backbone de YOLOv3 y YOLOv4, conocido por su velocidad.\n",
    "- Swin-Transformer ofrece una gran capacidad de capturar detalles contextuales a múltiples escalas.\n",
    "\n",
    "## 2.2 Decidir el framework: YOLO vs Faster R-CNN\n",
    "YOLO (You Only Look Once): Si buscas velocidad y buena precisión, YOLO es una excelente opción, especialmente para aplicaciones en tiempo real. Además, es más fácil de entrenar y ajustar en comparación con Faster R-CNN.\n",
    "Faster R-CNN: Si tienes imágenes de alta resolución y necesitas una detección precisa, podrías optar por Faster R-CNN, que tiende a ser más preciso en la detección, aunque a costa de velocidad.\n",
    "\n",
    "\n",
    "## 2.3 Uso de YOLOPd\n",
    "El paper que mencionas combina YOLO con R-CNN y otros mecanismos de atención para mejorar la precisión en la detección. YoloPd parece ser una versión optimizada, combinando la simplicidad de YOLO con la precisión de Faster R-CNN y mecanismos de atención (como Vision Transformer).\n",
    "\n",
    "Puedes comenzar probando modelos preentrenados de YOLOv5 o YOLOv8, que son versiones más recientes y mejoradas, y luego ajustar o integrar atención con ViT si es necesario.\n",
    "\n",
    "### Seguir consultando una vez lleguemos al uso de YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.17.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting keras\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\administrador.crisasusestudio\\desktop\\projects\\countingpenguins\\env\\lib\\site-packages (3.9.2)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\administrador.crisasusestudio\\desktop\\projects\\countingpenguins\\env\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting setuptools (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading setuptools-75.2.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\administrador.crisasusestudio\\desktop\\projects\\countingpenguins\\env\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading grpcio-1.67.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting rich (from keras)\n",
      "  Downloading rich-13.9.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.13.0-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "     ---------------------------------------- 0.0/48.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 48.7/48.7 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\administrador.crisasusestudio\\desktop\\projects\\countingpenguins\\env\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\administrador.crisasusestudio\\desktop\\projects\\countingpenguins\\env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\administrador.crisasusestudio\\desktop\\projects\\countingpenguins\\env\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\administrador.crisasusestudio\\desktop\\projects\\countingpenguins\\env\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\administrador.crisasusestudio\\desktop\\projects\\countingpenguins\\env\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\administrador.crisasusestudio\\desktop\\projects\\countingpenguins\\env\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\administrador.crisasusestudio\\desktop\\projects\\countingpenguins\\env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\administrador.crisasusestudio\\desktop\\projects\\countingpenguins\\env\\lib\\site-packages (from rich->keras) (2.18.0)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrador.crisasusestudio\\desktop\\projects\\countingpenguins\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached tensorflow-2.17.0-cp312-cp312-win_amd64.whl (2.0 kB)\n",
      "Using cached tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl (385.2 MB)\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.4/1.2 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "   ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/38.8 MB 30.1 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 2.0/38.8 MB 25.6 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 3.0/38.8 MB 24.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 4.1/38.8 MB 23.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 5.4/38.8 MB 24.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 6.6/38.8 MB 24.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 8.0/38.8 MB 25.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 9.2/38.8 MB 25.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 10.4/38.8 MB 25.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 11.6/38.8 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 13.1/38.8 MB 27.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 14.6/38.8 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 16.0/38.8 MB 28.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 16.9/38.8 MB 28.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 18.0/38.8 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 19.4/38.8 MB 27.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 20.7/38.8 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 22.2/38.8 MB 28.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 23.6/38.8 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 24.6/38.8 MB 27.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 25.9/38.8 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 27.4/38.8 MB 28.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 28.9/38.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.3/38.8 MB 29.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.6/38.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.1/38.8 MB 28.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.3/38.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.6/38.8 MB 29.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.1/38.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.6/38.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/38.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/38.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/38.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/38.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/38.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/38.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/38.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/38.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.8/38.8 MB 13.9 MB/s eta 0:00:00\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.6/3.0 MB 51.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.0/3.0 MB 38.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.0/3.0 MB 38.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 21.3 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "   ---------------------------------------- 0.0/127.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 122.9/127.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 127.5/127.5 kB 1.9 MB/s eta 0:00:00\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp312-cp312-win_amd64.whl (283 kB)\n",
      "   ---------------------------------------- 0.0/283.5 kB ? eta -:--:--\n",
      "   --------------------------------------  276.5/283.5 kB 16.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 283.5/283.5 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading rich-13.9.3-py3-none-any.whl (242 kB)\n",
      "   ---------------------------------------- 0.0/242.2 kB ? eta -:--:--\n",
      "   -------------------------------------- - 235.5/242.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 242.2/242.2 kB 4.9 MB/s eta 0:00:00\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.67.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 1.5/4.3 MB 31.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.1/4.3 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 34.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 23.0 MB/s eta 0:00:00\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.9/71.9 kB ? eta 0:00:00\n",
      "Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 413.4/413.4 kB 26.9 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.4/5.5 MB 29.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.6/5.5 MB 27.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.2/5.5 MB 29.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 32.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 25.2 MB/s eta 0:00:00\n",
      "Downloading setuptools-75.2.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 1.2/1.2 MB 37.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 20.0 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl (102 kB)\n",
      "   ---------------------------------------- 0.0/102.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 102.2/102.2 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "   ---------------------------------------- 0.0/70.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 70.4/70.4 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "   ---------------------------------------- 0.0/106.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 106.3/106.3 kB 6.0 MB/s eta 0:00:00\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "   ---------------------------------------- 0.0/126.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 126.3/126.3 kB ? eta 0:00:00\n",
      "Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "   ---------------------------------------- 0.0/227.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 227.6/227.6 kB 13.6 MB/s eta 0:00:00\n",
      "Downloading wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "   ---------------------------------------- 0.0/67.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 67.1/67.1 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorboard-data-server, setuptools, protobuf, opt-einsum, numpy, mdurl, MarkupSafe, markdown, idna, grpcio, google-pasta, gast, charset-normalizer, absl-py, werkzeug, requests, optree, opencv-python, ml-dtypes, markdown-it-py, h5py, astunparse, tensorboard, rich, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 charset-normalizer-3.4.0 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.67.0 h5py-3.12.1 idna-3.10 keras-3.6.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-1.26.4 opencv-python-4.10.0.84 opt-einsum-3.4.0 optree-0.13.0 protobuf-4.25.5 requests-2.32.3 rich-13.9.3 setuptools-75.2.0 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 termcolor-2.5.0 typing-extensions-4.12.2 urllib3-2.2.3 werkzeug-3.0.4 wheel-0.44.0 wrapt-1.16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Administrador.CRISASUSESTUDIO\\Desktop\\projects\\CountingPenguins\\env\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Administrador.CRISASUSESTUDIO\\Desktop\\projects\\CountingPenguins\\env\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Instalar YOLO y sus dependencias\n",
    "!pip install tensorflow keras opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Descargar el modelo YOLO preentrenado\n",
    "Para este ejemplo, vamos a usar YOLOv5 de la biblioteca de Ultralytics, que es una de las implementaciones más populares y fáciles de usar. Puedes clonar su repositorio y seguir las instrucciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clonar el repositorio de YOLOv5\n",
    "git clone https://github.com/ultralytics/yolov5.git\n",
    "cd yolov5\n",
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Cargar el modelo preentrenado\n",
    "Una vez que tengas la biblioteca YOLOv5 instalada, puedes cargar un modelo preentrenado fácilmente. Aquí hay un ejemplo de cómo hacerlo en un script de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Cargar el modelo preentrenado (puedes usar 'yolov5s', 'yolov5m', 'yolov5l', 'yolov5x')\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "# Establecer el modelo en modo de evaluación\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Realizar detección en imágenes\n",
    "Una vez que tengas el modelo, puedes usarlo para hacer detección en imágenes. Aquí te muestro cómo hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Cargar una imagen (asegúrate de tener la ruta correcta a la imagen)\n",
    "image_path = 'ruta/a/tu/imagen.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Realizar la detección\n",
    "results = model(image)\n",
    "\n",
    "# Mostrar los resultados\n",
    "results.show()  # Muestra la imagen con bounding boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5: Procesar los resultados\n",
    "Los resultados de YOLO contienen información sobre las detecciones, incluyendo las coordenadas de las cajas delimitadoras, las clases y las puntuaciones de confianza. Aquí tienes un ejemplo de cómo acceder a esta información:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las detecciones\n",
    "detections = results.xyxy[0]  # formato [x1, y1, x2, y2, conf, class]\n",
    "\n",
    "for detection in detections:\n",
    "    x1, y1, x2, y2, conf, cls = detection.numpy()\n",
    "    print(f'Clase: {model.names[int(cls)]}, Confianza: {conf:.2f}, Coordenadas: [{x1:.0f}, {y1:.0f}, {x2:.0f}, {y2:.0f}]')\n",
    "\n",
    "# Si quieres dibujar las detecciones en la imagen\n",
    "for detection in detections:\n",
    "    x1, y1, x2, y2, conf, cls = detection.numpy()\n",
    "    cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)  # Dibuja la caja\n",
    "    cv2.putText(image, f'{model.names[int(cls)]} {conf:.2f}', (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "# Mostrar la imagen con detecciones\n",
    "cv2.imshow('Detección', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 6: Ajustar el modelo para tu caso específico (opcional)\n",
    "Si quieres mejorar la precisión del modelo para detectar pingüinos específicamente, puedes hacer fine-tuning del modelo preentrenado usando tu propio conjunto de datos. Esto implicaría:\n",
    "\n",
    "Preparar un conjunto de datos con tus imágenes y anotaciones.\n",
    "Entrenar el modelo usando el conjunto de datos específico. Para esto, puedes seguir las instrucciones de entrenamiento en el repositorio de YOLOv5.\n",
    "Conclusión\n",
    "Estos pasos te permitirán empezar a trabajar con un modelo YOLO preentrenado utilizando Keras y PyTorch. Si decides hacer fine-tuning o necesitas más ayuda sobre cómo ajustar el modelo, no dudes en preguntar. ¡Buena suerte con tu proyecto!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
